
# 視障者智慧閱讀系統：影像識別轉語音輔助專題

## 1. 主題（專題方向）
**影像識別輔助視障者閱讀文字，並將其轉為語音輸出**

目標是開發一套能透過影像辨識技術擷取現實生活中的文字資訊並即時以語音的方式輸出的視障者輔助系統，協助視障或低視力者獨立閱讀與理解周遭文字資訊。

---

## 2. 動機（為什麼想做這個）

- **視障者面臨資訊落差問題**：生活中充滿文字資訊（如公車路線、藥品標籤、餐廳菜單等），但視障者無法快速獲取這些資訊。
- **目前解決方案成本高、語言限制**：市面上的輔助工具多為進口產品，其價格昂貴或僅支援英文，對中文使用者幫助有限。
- **現在的技術門檻降低，應用機會成熟**：光學字元辨識 (OCR) 與語音合成（TTS）技術已成熟，透過手機或嵌入式裝置即可實作。

---

## 3. 相關文獻參考

| 論文 / 資源 | 貢獻內容 |
|-------------|----------|
| [ACM Visual Assistance System for the Visually Impaired people based on Image Recognition Technology](https://dl.acm.org/doi/10.1145/3510858.3511377) | 最一開始在ACM看到的視障輔助文章 |
| Seeing AI（Microsoft Research） | 導入視障者可使用的多功能辨識系統，包括文字、臉部、情境等辨識。 |
| Lookout App（Google Research） | 探討如何在低計算資源下實作高效 OCR 與物件辨識。 |
| [Tesseract OCR](https://github.com/tesseract-ocr/tesseract) | 主流開源 OCR 工具，支援多語言，包含繁體中文。 |
| [Coqui TTS](https://github.com/coqui-ai/TTS) | 開源語音合成工具，支援多語言語音輸出，可客製化。 |
| Real-Time Scene Text Detection with DBNet | 用於即時擷取自然場景中文字的研究。 |


---

## 4. 問題與解決方法

| 問題 | 解決方法 |
|------|----------|
| OCR 在自然環境下辨識不穩定 | 加入文字偵測模組（如 EAST / DBNet）先定位文字區域 |
| 手寫字或特殊字體影響辨識率 | 使用深度學習 OCR 模型（如 CRNN、TrOCR） |
| 中文語音輸出自然度不佳 | 使用 Google TTS 或 Coqui TTS |
| 視障者無法操作複雜介面 | 簡化操作流程，設計語音觸發或「拍一下就唸」 |
| 易讀錯段落 | 設計使用者選擇區域方式（如手指指哪讀哪） |

---

## 5. 實現步驟、方法、技術

### 系統架構：
使用者端（手機或攝像頭）→ 拍攝畫面 → 影像預處理 → OCR 文字辨識 → TTS 語音輸出

### 主要模組與技術：

| 功能 | 技術 / 工具 |
|------|--------------|
| 圖像擷取 | 手機鏡頭 / Raspberry Pi + Camera |
| 文字偵測 | EAST / DBNet / OpenCV |
| OCR 模型 | Tesseract OCR（支援中文）或 TrOCR |
| 語音輸出 | Google TTS / Coqui TTS |
| UI 介面 | Android / Python + Flask / Streamlit |
| 語音控制（選配） | Google Speech-to-Text / Whisper |


---

## 6. 預期結果

- 使用者可透過拍照或語音指令讓系統讀出圖像中的中文文字。
- 支援自然場景中的文字資訊（如招牌、菜單、標籤）。
- 提供中文語音輸出，協助視障者理解環境資訊。
- 系統可展示於手機或筆電上進行 Demo。